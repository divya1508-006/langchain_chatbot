{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e759a92d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7614bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d089daa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2d0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634251ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002372B4E4290>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002372B824690>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01c75768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Divya, it's nice to meet you! ðŸ‘‹\\n\\nWhat can I do for you today? ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 17, 'total_tokens': 43, 'completion_time': 0.047272727, 'prompt_time': 0.001900629, 'queue_time': 0.15909208100000002, 'total_time': 0.049173356}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ddb9e9f2-e66f-4187-a1d5-4518cc0028cf-0', usage_metadata={'input_tokens': 17, 'output_tokens': 26, 'total_tokens': 43})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is Divya!\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0034f173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You got it! Hello Harshit, I remember you're a GenAI mentor.  \\n\\nIs there anything I can help you with today regarding your work with GenAI? ðŸ¤” Perhaps you have a question about a specific model, need help brainstorming training data, or want to discuss ethical considerations in AI?  \\n\\nI'm here to assist however I can! ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 70, 'total_tokens': 148, 'completion_time': 0.141818182, 'prompt_time': 0.004112376, 'queue_time': 0.021007123, 'total_time': 0.145930558}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ea923b3b-42ff-4dba-9c9d-c4ec8a96f150-0', usage_metadata={'input_tokens': 70, 'output_tokens': 78, 'total_tokens': 148})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is Harshit and I'm GenAI mentor!\"),\n",
    "        AIMessage(content=\"Hi Harshit, it's nice to meet you! ðŸ”¥ What can I do for you today? ðŸ˜Š\"),\n",
    "        HumanMessage(content=\"Hello Again! Do you remember my name and what I do professionally?\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f2b8ef",
   "metadata": {},
   "source": [
    "### Message History \n",
    "We can use a Message History class to wrap our model and make it stateful. This will keep track of inputs and outputs of the model, and store them in some datastore, Future interactions will then load those messages and pass them into the chain as part of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61d255c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "557788bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da777f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\": \"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24c77c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Divya, it's nice to meet you!\n",
      "\n",
      "I'm glad you reached out. \n",
      "\n",
      "What can I do for you today? Are you working on a school project, or just curious to chat? ðŸ˜Š  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response= with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is Divya and I.m a student\"),\n",
    "    ],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b550ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve1 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Do you remember my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19156bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Yes, I do!  I remember you're Divya. ðŸ˜Š \\n\\nIs there anything I can help you with, Divya?  Perhaps you have a question about something you're learning in school? ðŸ“š  Or maybe you just want to talk about your day?  I'm here to listen.  ðŸ‘‚\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 86, 'total_tokens': 157, 'completion_time': 0.129090909, 'prompt_time': 0.005916421, 'queue_time': 0.14164454699999998, 'total_time': 0.13500733}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--1693bad1-9c12-4205-8e5e-3df026c82280-0' usage_metadata={'input_tokens': 86, 'output_tokens': 71, 'total_tokens': 157}\n"
     ]
    }
   ],
   "source": [
    "print(retrieve1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17c9176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve2 = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Do you remember my profession?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4ebf021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"As I said before, I don't have memory of past conversations.  \\n\\nSo, I don't remember you telling me your profession.  If you'd like to tell me, I'm all ears!  ðŸ‘‚  \\n\\n\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 245, 'total_tokens': 298, 'completion_time': 0.096363636, 'prompt_time': 0.015127636, 'queue_time': 0.234689066, 'total_time': 0.111491272}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--ce09b796-8b14-463b-8e7b-44140f0d3578-0' usage_metadata={'input_tokens': 245, 'output_tokens': 53, 'total_tokens': 298}\n"
     ]
    }
   ],
   "source": [
    "print(retrieve2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c89681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"As a large language model, I have no memory of past conversations. If you'd like to tell me your name, I'd be happy to remember it for the duration of our current conversation.\\n\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 15, 'total_tokens': 59, 'completion_time': 0.08, 'prompt_time': 0.001905847, 'queue_time': 0.016551642000000002, 'total_time': 0.081905847}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--47433f11-5157-4d91-954a-3665d13a3af6-0' usage_metadata={'input_tokens': 15, 'output_tokens': 44, 'total_tokens': 59}\n"
     ]
    }
   ],
   "source": [
    "config2 = {\"configurable\": {\"session_id\":\"chat2\"}}\n",
    "new_retrieve = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Do you remember my name?\")],\n",
    "    config=config2\n",
    ")\n",
    "print(new_retrieve)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
