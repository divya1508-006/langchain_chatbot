{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc7f336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25492b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43db0201",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6a7ad73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000243E29EBCD0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000243E29D94D0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\", groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "743259ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Divya, it's nice to meet you! ðŸ˜Š \\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 17, 'total_tokens': 43, 'completion_time': 0.047272727, 'prompt_time': 0.001900407, 'queue_time': 0.035567638, 'total_time': 0.049173134}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--11dd4608-444c-431a-b60d-623ff1dd5e19-0', usage_metadata={'input_tokens': 17, 'output_tokens': 26, 'total_tokens': 43})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage \n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is Harshit and I'm GenAI mentor!\"),\n",
    "        AIMessage(content=\"Hi Harshit, it's nice to meet you! ðŸ”¥ What can I do for you today? ðŸ˜Š\"),\n",
    "        HumanMessage(content=\"Hello Again! Do you remember my name and what I do professionally?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, my name is Divya!\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cf5cf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Yes, I do! I remember that you're Harshit, a GenAI mentor.  \\n\\nIs there anything I can help you with today regarding your work as a GenAI mentor? Perhaps you have a question about a specific model, need help explaining a concept to a student, or are looking for resources for your mentees? ðŸ˜„  \\n\\nI'm here to assist in any way I can! ðŸ’ª\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 70, 'total_tokens': 157, 'completion_time': 0.158181818, 'prompt_time': 0.003657114, 'queue_time': 0.018673823, 'total_time': 0.161838932}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--b21d13d3-5f97-45d4-9cca-221afc8a9262-0', usage_metadata={'input_tokens': 70, 'output_tokens': 87, 'total_tokens': 157})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, my name is Harshit and I'm GenAI mentor!\"),\n",
    "        AIMessage(content=\"Hi Harshit, it's nice to meet you! ðŸ”¥ What can I do for you today? ðŸ˜Š\"),\n",
    "        HumanMessage(content=\"Hello Again! Do you remember my name and what I do professionally?\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32134e6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'with_message_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Add the coffee steps into session 'chat1'\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mwith_message_history\u001b[49m.invoke(\n\u001b[32m      3\u001b[39m     [\n\u001b[32m      4\u001b[39m         HumanMessage(content=\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[33mSteps to prepare the Coffee:\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[33m1. Choose Your Coffee â€“ Pick your favorite coffee beans or ground coffee.\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m2. Measure the Coffee â€“ Use about 1â€“2 tablespoons of ground coffee per 6 ounces of water.\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m3. Heat the Water â€“ Ideal temperature is around 90â€“96Â°C (not boiling).\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[33m4. Brew the Coffee â€“ Use a drip machine, French press, espresso maker, or any method you prefer.\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m5. Wait & Extract â€“ Let it brew for the right amount of time (e.g., 4 minutes for a French press).\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33m6. Serve & Enjoy â€“ Pour into your favorite mug, add milk, sugar, or enjoy it black!\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     13\u001b[39m     ],\n\u001b[32m     14\u001b[39m     config=config  \u001b[38;5;66;03m# session_id = \"chat1\"\u001b[39;00m\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Ask the model to explain each step in detail\u001b[39;00m\n\u001b[32m     18\u001b[39m coffee_response = with_message_history.invoke(\n\u001b[32m     19\u001b[39m     [HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mCan you explain each step in detail?\u001b[39m\u001b[33m\"\u001b[39m)],\n\u001b[32m     20\u001b[39m     config=config\n\u001b[32m     21\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'with_message_history' is not defined"
     ]
    }
   ],
   "source": [
    "# Add the coffee steps into session 'chat1'\n",
    "with_message_history.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"\"\"\n",
    "Steps to prepare the Coffee:\n",
    "1. Choose Your Coffee â€“ Pick your favorite coffee beans or ground coffee.\n",
    "2. Measure the Coffee â€“ Use about 1â€“2 tablespoons of ground coffee per 6 ounces of water.\n",
    "3. Heat the Water â€“ Ideal temperature is around 90â€“96Â°C (not boiling).\n",
    "4. Brew the Coffee â€“ Use a drip machine, French press, espresso maker, or any method you prefer.\n",
    "5. Wait & Extract â€“ Let it brew for the right amount of time (e.g., 4 minutes for a French press).\n",
    "6. Serve & Enjoy â€“ Pour into your favorite mug, add milk, sugar, or enjoy it black!\n",
    "\"\"\")\n",
    "    ],\n",
    "    config=config  # session_id = \"chat1\"\n",
    ")\n",
    "\n",
    "# Ask the model to explain each step in detail\n",
    "coffee_response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Can you explain each step in detail?\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(coffee_response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
